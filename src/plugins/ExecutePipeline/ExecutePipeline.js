/*globals define*/
/*jshint node:true, browser:true, esversion: 6*/

/**
 * Generated by PluginGenerator 1.7.0 from webgme on Tue May 03 2016 16:52:39 GMT-0500 (CDT).
 */

define([
    'q',
    'text!./metadata.json',
    'plugin/PluginBase',
    './Templates',
    'executor/ExecutorClient',
    'jszip'
], function (
    Q,
    pluginMetadata,
    PluginBase,
    Templates,
    ExecutorClient,
    JsZip
) {
    'use strict';

    pluginMetadata = JSON.parse(pluginMetadata);
    /**
     * Initializes a new instance of ExecutePipeline.
     * @class
     * @augments {PluginBase}
     * @classdesc This class represents the plugin ExecutePipeline.
     * @constructor
     */
    var ExecutePipeline = function () {
        // Call base class' constructor.
        PluginBase.call(this);
        this.pluginMetadata = pluginMetadata;
        this.opFor = {};
        this.incomingCounts = {};
        this.outputsOf = {};
        this.nodes = {};
        this.inputs = {};

        this.finished = {};
        this.completedCount = 0;
        this.totalCount = 0;
    };

    /**
     * Metadata associated with the plugin. Contains id, name, version, description, icon, configStructue etc.
     * This is also available at the instance at this.pluginMetadata.
     * @type {object}
     */
    ExecutePipeline.metadata = pluginMetadata;
    ExecutePipeline.UPDATE_INTERVAL = 1500;

    // Prototypical inheritance from PluginBase.
    ExecutePipeline.prototype = Object.create(PluginBase.prototype);
    ExecutePipeline.prototype.constructor = ExecutePipeline;

    /**
     * Main function for the plugin to execute. This will perform the execution.
     * Notes:
     * - Always log with the provided logger.[error,warning,info,debug].
     * - Do NOT put any user interaction logic UI, etc. inside this method.
     * - callback always has to be called even if error happened.
     *
     * @param {function(string, plugin.PluginResult)} callback - the result callback
     */
    ExecutePipeline.prototype.main = function (callback) {
        // This will probably need to execute the operations, too, because the
        // inputs for the next operation cannot be created until the inputs have
        // been generated
        this._callback = callback;
        this.core.loadChildren(this.activeNode)
            .then(children => {
                // For each child, we need to organize them by the number of incoming connections
                // AND the corresponding incoming connections. When a connection is given data,
                // all the operations using that data can be decremented. If the remaining
                // incoming connection count is zero, execute the given operation
                //

                // Get a node
                var child = children.filter(c =>
                    this.core.getAttribute(c, 'name') === 'SGD'
                ).shift();

                this.parsePipeline(children);

                if (this.getCurrentConfig().reset) {
                    // Clear the pipeline's results
                    this.logger.info('Clearing all intermediate pipeline results');
                    Object.keys(this.nodes).map(nodeId => this.nodes[nodeId])
                        .filter(node =>  // get all connections
                            !(this.core.getPointerPath(node, 'src') && this.core.getPointerPath(node, 'dst'))
                        )
                        .forEach(conn => this.core.delAttribute(conn, 'data'));
                }

                // Execute the operations in the proper order
                this.executePipeline();
            })
            .fail(e => console.error(e));

    };

    //////////////////////////// Operation Preparation/Execution ////////////////////////////
    // Organize the operations by input data and output data (and count)
    ExecutePipeline.prototype.parsePipeline = function (nodes) {
        var operations,
            conns,
            connId,
            nodeId,
            i;

        this.completedCount = 0;
        // Cache all nodes
        nodes.forEach(node => this.nodes[this.core.getPath(node)] = node);

        // Get all connections
        conns = nodes.filter(node =>
            this.core.getPointerPath(node, 'src') && this.core.getPointerPath(node, 'dst')
        );

        // Get all operations
        nodes
            .filter(node => conns.indexOf(node) === -1)
            .forEach(node => {
                var nodeId = this.core.getPath(node);
                this.incomingCounts[nodeId] = 0;
                this.finished[nodeId] = false;
                this.inputs[nodeId] = [];

                this.totalCount++;
            });

        // Store the operations by their...
        //    - incoming conns (connId => [ops]) (for updating which nodes come next)
        for (i = conns.length; i--;) {
            connId = this.core.getPath(conns[i]);
            nodeId = this.core.getPointerPath(conns[i], 'dst');
            this.opFor[connId] = nodeId;

            //    - incoming counts
            this.incomingCounts[nodeId]++;
            this.inputs[nodeId].push(connId);
        }

        //    - output conns
        for (i = conns.length; i--;) {
            connId = this.core.getPath(conns[i]);
            nodeId = this.core.getPointerPath(conns[i], 'src');
            if (!this.outputsOf[nodeId]) {
                this.outputsOf[nodeId] = [connId];
            } else {
                this.outputsOf[nodeId].push(connId);
            }
        }
    };

    ExecutePipeline.prototype.executePipeline = function() {
        this.logger.debug(`starting pipeline`);
        this.executeReadyOperations();
    };

    ExecutePipeline.prototype.onPipelineComplete = function(err) {
        var name = this.core.getAttribute(this.activeNode, 'name');
        this.logger.debug(`Pipeline "${name}" complete!`);

        this.save('Pipeline execution finished')
            .then(() => {
                this.result.setSuccess(!err);
                this._callback(null, this.result);
            })
            .fail(e => console.error(e));
    };

    ExecutePipeline.prototype.executeReadyOperations = function () {
        // Get all operations with incomingCount === 0
        var operations = Object.keys(this.incomingCounts),
            readyOps = operations.filter(name => this.incomingCounts[name] === 0);

        this.logger.info(`About to execute ${readyOps.length} operations`);
        // Execute all ready operations
        readyOps.forEach(opId => {
            delete this.incomingCounts[opId];
            this.executeOperation(opId);
        });
        return readyOps.length;
    };

    ExecutePipeline.prototype.executeOperation = function (opId) {
        var node = this.nodes[opId],
            name = this.core.getAttribute(node, 'name'),
            localTypeId = this.getLocalOpType(node),
            artifact,
            artifactName,
            files,
            inputs;

        // Execute any special operation types here - not on an executor
        if (localTypeId !== null) {
            this.executeLocalOperation(localTypeId, node);
        } else {
            // Generate all execution files
            this.createOperationFiles(node).then(results => {
                files = results;
                artifactName = name + '-execution-files';
                artifact = this.blobClient.createArtifact(artifactName);

                // Add the input assets
                //   - get the metadata (name)
                //   - add the given inputs
                inputs = Object.keys(files.inputAssets);

                return Q.all(
                    inputs.map(input => {  // Get the metadata for each input
                        var hash = files.inputAssets[input];

                        // data asset for "input"
                        return this.blobClient.getMetadata(hash);
                    })
                );
            })
            .then(mds => {
                // get (input, filename) tuples
                var data = {},
                    tuples,
                    outputs,
                    config;

                tuples = mds.forEach((metadata, i) => {
                    // add the hashes for each input
                    var input = inputs[i], 
                        name = metadata.name,
                        hash = files.inputAssets[input];

                    data['inputs/' + input + '/' + name] = hash;
                });

                delete files.inputAssets;

                // Add pointer assets
                Object.keys(files.ptrAssets)
                    .forEach(path => data[path] = files.ptrAssets[path]);

                delete files.ptrAssets;

                // Add the executor config
                outputs = this._parseArgs(this.core.getAttribute(node, 'outputs'))
                    .map(pair => pair[0])
                    .map(name => {
                        return {
                            name: name,
                            resultPatterns: [`outputs/${name}/**`]
                        };
                    });
                var debugging = [
                    {
                        name: name + '-all-files',
                        resultPatterns: []
                    }
                ];

                config = {
                    cmd: 'th',
                    args: ['init.lua'],
                    resultArtifacts: outputs.concat(debugging)
                };
                files['executor_config.json'] = JSON.stringify(config, null, 4);

                // Save the artifact
                return artifact.addObjectHashes(data);
            })
            .then(() => {
                this.logger.info(`Added ptr/input data hashes for "${artifactName}"`);
                return artifact.addFiles(files);
            })
            .then(() => {
                this.logger.info(`Added execution files for "${artifactName}"`);
                return artifact.save();
            })
            .then(hash => {
                this.logger.info(`Saved execution files "${artifactName}"`);
                this.result.addArtifact(hash);  // Probably only need this for debugging...
                this.executeDistOperation(node, hash);
            })
            .fail(e => {
                this.logger.error(`Distributed operation "${name}" failed ${e}`);
            });
        }
    };

    ExecutePipeline.prototype.executeDistOperation = function (node, hash) {
        var name = this.core.getAttribute(node, 'name'),
            nodeId = this.core.getPath(node),
            executor = new ExecutorClient({
                logger: this.logger,
                serverPort: this.gmeConfig.server.port
            });

        this.logger.info(`Executing operation "${name}"`);

        // Run the operation on an executor
        executor.createJob({hash})
            .then(() => this.watchOperation(executor, hash, nodeId))
            .catch(err => this.logger.error(`Could not execute "${name}": ${err}`));

    };

    ExecutePipeline.prototype.watchOperation = function (executor, hash, nodeId) {
        return executor.getInfo(hash)
            .then(info => {
                if (info.status === 'CREATED' || info.status === 'RUNNING') {
                    setTimeout(
                        this.watchOperation.bind(this, executor, hash, nodeId),
                        ExecutePipeline.UPDATE_INTERVAL
                    );
                    return;
                }

                if (info.status !== 'SUCCESS') {
                    var name = this.core.getAttribute(this.nodes[nodeId], 'name');
                    this.logger.error(`Operation "${nodeId}" failed! ${JSON.stringify(info)}`);
                    // Download all files
                    this.result.addArtifact(info.resultHashes[name + '-all-files']);
                    this.onPipelineComplete(`Operation "${nodeId}" failed! ${info}`);  // Failed
                } else {
                    var name = this.core.getAttribute(this.nodes[nodeId], 'name');
                    if (this.getCurrentConfig().debug) {
                        this.result.addArtifact(info.resultHashes[name + '-all-files']);
		    }
                    this.onDistOperationComplete(nodeId, info);
                }
            })
            .catch(err => this.logger.error(`Could not get op info for ${nodeId}: ${err}`));
    };

    ExecutePipeline.prototype.onDistOperationComplete = function (nodeId, result) {
        var outputIds = this.outputsOf[nodeId] || [],
            nodes = outputIds.map(id => this.nodes[id]),
            node = this.nodes[nodeId],
            outputs;

        // Match the output names to the actual nodes
        // Create an array of [name, node]
        // For now, just match by type. Later we may use ports for input/outputas
        // TODO
        outputs = this._parseArgs(this.core.getAttribute(node, 'outputs'))
            .map(pair => {
                var name = pair[0],
                    type = pair[1];

                // Find a node with the given base type
                for (var i = nodes.length; i--;) {
                    if (this.isMetaTypeOf(nodes[i], this.META[type])) {
                        return [name, nodes[i]];
                    }
                }
                throw `Multiple outputs w/ same type not fully supported ${nodeId}`;
            });
            

        // Store the results in the outgoing connections
        var artifactPs = outputs.map(pair => {
            var name = pair[0],
                node = pair[1],
                hash;

            // FIXME: this should not be in directories -> flatten the data!
            // Ideally, this would be performed on the worker -> not on DeepForge
            // get the files from the hash
            return this.blobClient.getObject(result.resultHashes[name]);
        });
        Q.all(artifactPs)
            .then(objects => {
                this.logger.info(`preparing outputs -> retrieved ${objects.length} objects`);
                return Q.all(
                    objects.map((object, index) => {
                        var output = new JsZip();

                        return output.load(object);
                    })
                );
            })
            .then(zipfiles => {
                return Q.all(
                    zipfiles.map((zip, index) => {
                        var pair = outputs[index],
                            name = pair[0],
                            connNode = pair[1],
                            artifact = this.blobClient.createArtifact(name),
                            files = {};

                    // move the files from /outputs/<name> to /
                    Object.keys(zip.files)
                        .forEach(filename => {
                            var newName = filename.replace('outputs/' + name + '/', '');
                            files[newName] = zip.files[filename].asArrayBuffer();
                        });

                    // save artifact and get the new hash
                    return artifact.addFiles(files)
                        .then(() => artifact.save())
                        .then(hash => {
                            // store the new hash in the connection
                            this.core.setAttribute(connNode, 'data', hash);
                        });
                    })
                );
            })
            .then(() => this.onOperationComplete(node))
            .fail(e => this.onPipelineComplete(`Operation ${nodeId} failed: ${e}`));
    };

    ExecutePipeline.prototype.onOperationComplete = function (node) {
        var name = this.core.getAttribute(node, 'name'),
            nodeId = this.core.getPath(node),
            outputs = this.outputsOf[nodeId] || [],
            hasReadyOps;


        // For all the outputs, decrement the corresponding operation's incoming counts
        hasReadyOps = outputs.map(id => this.opFor[id])
            .reduce((l1, l2) => l1.concat(l2), [])

            // decrement the incoming counts for each operation id
            .map(opId => --this.incomingCounts[opId])
            .indexOf(0) > -1;

        this.completedCount++;
        this.logger.info(`Operation "${name}" completed. ` + 
            `${this.totalCount - this.completedCount} remaining.`);
        if (hasReadyOps) {
            this.executeReadyOperations();
        } else if (this.completedCount === this.totalCount) {
            this.onPipelineComplete();
        }
    };

    //////////////////////////// Operation File/Dir Creators ////////////////////////////
    ExecutePipeline.prototype.createOperationFiles = function (node) {
        var files = {};
        // For each operation, generate the output files:
        //   inputs/<arg-name>/init.lua  (respective data deserializer)
        //   pointers/<name>/init.lua  (result of running the main plugin on pointer target - may need a rename)
        //   outputs/<name>/  (make dirs for each of the outputs)
        //   outputs/init.lua  (serializers for data outputs)
        //
        //   attributes.lua (returns lua table of operation attributes)
        //   init.lua (main file -> calls main and serializes outputs)
        //   <name>.lua (entry point -> calls main operation code)

        // add the given files
        this.createEntryFile(node, files);
        this.createInputs(node, files);
        this.createOutputs(node, files);
        this.createMainFile(node, files);
        this.createAttributeFile(node, files);
        return Q.ninvoke(this, 'createPointers', node, files);
    };

    ExecutePipeline.prototype.createInputs = function (node, files) {
        var nodeId = this.core.getPath(node),
            inputIds = this.inputs[nodeId],
            inputs = this._parseArgs(this.core.getAttribute(node, 'inputs'));

        // For each input, match the connection with the input name
        //   [ name, type ] => [ name, type, node ]
        if (inputIds.length > 1) {
            this.logger.warn(`multiple inputs not yet supported!`);
        }
        inputs[0].push(this.nodes[inputIds[0]]);

        // For each input,
        //  - create the deserializer
        //  - put it in inputs/<name>/init.lua
        //  - copy the data asset to /inputs/<name>/init.lua
        files.inputAssets = {};  // data assets
        inputs.forEach(pair => {
            var name = pair[0],
                type = pair[1],
                node = pair[2],
                content;

            // Create the deserializer
            content = {
                name: name,
                code: this.core.getAttribute(this.META[type], 'deserialize')
            };
            files['inputs/' + name + '/init.lua'] = _.template(Templates.DESERIALIZE)(content);

            // copy the data asset to /inputs/<name>/
            // storing the hash for now...
            files.inputAssets[name] = this.core.getAttribute(node, 'data');
        });
    };

    ExecutePipeline.prototype.createPointers = function (node, files, cb) {
        var pointers = this.core.getPointerNames(node).filter(name => name !== 'base'),
            nIds = pointers.map(p => this.core.getPointerPath(node, p));

        files.ptrAssets = {};
        Q.all(
            nIds.map(nId => this.core.loadByPath(this.rootNode, nId))
        )
        .then(nodes => {

            var len = nodes.length,
                executePlugin = function(pluginName, config, callback) {
                    // Call the Interpreter manager in a Q.ninvoke friendly way
                    // FIXME: I need to create a custom context for the given plugin:
                    //     - Set the activeNode to the given referenced node
                    //     - If the activeNode is namespaced, set META to the given namespace
                    //
                    WebGMEGlobal.InterpreterManager.run(pluginName, config, result => {
                        if (!result.success) {
                            return callback(result.getError());
                        }
                        console.log('Finished calling ' + pluginName);
                        callback(null, result.artifacts);
                    });
                };
                
            return Q.all(
                nodes.map(ptrNode => {
                    // Look up the plugin to use
                    var pluginName = this.core.getRegistry(ptrNode, 'validPlugins').split(' ').shift();
                    console.log(`generating code for ${this.core.getAttribute(ptrNode, 'name')} using ${pluginName}`);

                    // Add plugin config?
                    // TODO
                    var pluginConfig = {
                        activeNode: this.core.getPath(ptrNode)
                    };

                    // Load and run the plugin
                    return Q.nfcall(executePlugin, pluginName, pluginConfig);
                })
            );
        })
        .then(resultHashes => {
            var name = this.core.getAttribute(node, 'name');
            console.log(`Pointer generation for ${name} FINISHED!`);
            resultHashes.forEach((hashes, index) => {
                // Grab the first asset for now
                // FIXME
                files.ptrAssets[`pointers/${pointers[index]}/init.lua`] = hashes[0];
            });
            return cb(null, files);

            // For each hash:
            //   - retrieve the zip archive
            //   - get the generated files for the plugin
            //     - if only one file, rename it to `init.lua`
            //return Q.all(
                //resultHashes.map(hash => this.blobClient.getObjectAsString(hash))
            //);
        })
        // Add support for zip files
        // TODO
        //.then(objects =>
            //Q.all(objects.map(object => {
                    //var output = new JsZip();

                    //return output.load(object);
                //})
            //)
        //)
        //.then(zipfiles => {  // TODO
            //// If it generates one artifact, rename it to `init.lua`. Otherwise, expect
            //// an `init.lua` file
            //// TODO
            //console.log('zipfiles:', zipfiles);
            //cb(null, files);
        //})
        .fail(e => {
            this.logger.error(`Could not generate pointer files for ${this.core.getAttribute(node, 'name')}: ${JSON.stringify(e)}`);
            return cb(e);
        });
    };

    ExecutePipeline.prototype.createOutputs = function (node, files) {
        // For each of the output types, grab their serialization functions and
        // create the `outputs/init.lua` file
        var outputTypes,
            code;

        outputTypes = this._parseArgs(this.core.getAttribute(node, 'outputs'))
            .map(pair => pair[1])
            // Get the serialize functions for each
            .map(type => [type, this.core.getAttribute(this.META[type], 'serialize')]);

        // Remove duplicates
        // TODO

        files['outputs/init.lua'] = _.template(Templates.SERIALIZE)({types: outputTypes});
    };

    ExecutePipeline.prototype._parseArgs = function (args) {
        // parse arguments are in the form 'arg: Type1, arg2: Type2'
        // and return [[arg1, Type1], [arg2, Type2]]
        return args.split(',')
            .map(pair => pair.split(':').map(w => w.replace(/\s+/g, '')));

    };

    ExecutePipeline.prototype.createEntryFile = function (node, files) {
        var outputs = this._parseArgs(this.core.getAttribute(node, 'outputs')),
            name = this.core.getAttribute(node, 'name'),
            content = {};

        // sort the outputs by the return values?
        if (outputs.length > 1) {
            console.error('Multiple outputs not yet supported!');
        }

        // inputs and outputs
        content.name = name;
        content.outputs = outputs;

        files['init.lua'] = _.template(Templates.ENTRY)(content);
    };

    ExecutePipeline.prototype.createMainFile = function (node, files) {
        var inputs = this._parseArgs(this.core.getAttribute(node, 'inputs')),
            name = this.core.getAttribute(node, 'name'),
            code = this.core.getAttribute(node, 'code'),
            pointers = this.core.getPointerNames(node).filter(ptr => ptr !== 'base'),
            content = {
                name: name
            };

        // Get input data arguments
        content.inputs = inputs;

        // Defined variables for each pointers
        content.pointers = pointers;

        // Add remaining code
        content.code = code;

        files['main.lua'] = _.template(Templates.MAIN)(content);
    };

    ExecutePipeline.prototype.createAttributeFile = function (node, files) {
        var skip = ['outputs', 'inputs'],
            table;

        table = '{\n\t' + this.core.getAttributeNames(node)
            .filter(attr => skip.indexOf(attr) === -1)
            .map(name => [name, JSON.stringify(this.core.getAttribute(node, name))])
            .map(pair => pair.join(' = '))
            .join(',\n\t') + '\n}';

        files['attributes.lua'] = `-- attributes of ${this.core.getAttribute(node, 'name')}\nreturn ${table}`;
    };

    //////////////////////////// Special Operations ////////////////////////////
    ExecutePipeline.LOCAL_OPS = [
        'BlobLoader',
        'Save'
    ];

    ExecutePipeline.prototype.getLocalOpType = function (node) {
        var type;
        for (var i = ExecutePipeline.LOCAL_OPS.length; i--;) {
            type = ExecutePipeline.LOCAL_OPS[i];
            if (this.isMetaTypeOf(node, this.META[type])) {
                return type;
            }
        }
        return null;
    };

    ExecutePipeline.prototype.executeLocalOperation = function (type, node) {
        // Retrieve the given LOCAL_OP type
        if (!this[type]) {
            this.logger.error(`No local operation handler for ${type}`);
        }
        this.logger.info(`Running local operation ${type}`);

        return this[type](node);
    };

    // Should these be in lua?
    ExecutePipeline.prototype.BlobLoader = function(node) {
        var nodeId = this.core.getPath(node),
            hash = this.core.getAttribute(node, 'data'),
            outputs = this.outputsOf[nodeId].map(id => this.nodes[id]);

        this.logger.info(`Running BlobLoader for ${nodeId}`);

        // Get the 'data' hash and store it in the output connections
        outputs.forEach(output => this.core.setAttribute(output, 'data', hash));

        // Set the metadata as appropriate
        // TODO
        this.onOperationComplete(node);
    };

    ExecutePipeline.prototype.Save = function(node) {
        var nodeId = this.core.getPath(node),
            dstName = this.core.getAttribute(node, 'dst'),
            parentId = this.core.getPointerPath(node, 'target');
        
        // Overwrite existing node w/ this name?
        // TODO

        if (this.inputs[nodeId].length > 1) {
            this.logger.error(`multiple inputs not yet supported!`);
        }

        // Load the new parent node
        this.core.loadByPath(this.rootNode, parentId)
            .then(parent => {
                var newNode,
                    inputId = this.inputs[nodeId][0],
                    base = this.core.getBase(this.nodes[inputId]),
                    input;

                newNode = this.core.createNode({
                    base,
                    parent
                });

                this.core.setAttribute(newNode, 'name', dstName);
                this.logger.info(`Saving result as ${dstName} in ${this.core.getAttribute(parent, 'name')}`);
                // Attach the data
                input = this.core.getAttribute(this.nodes[inputId], 'data');
                this.core.setAttribute(newNode, 'data', input);

                this.onOperationComplete(node);
            });
    };

    return ExecutePipeline;
});
